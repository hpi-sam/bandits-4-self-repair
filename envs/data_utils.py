from scipy import statsimport numpy as npimport pandas as pdimport matplotlib.pyplot as pltdef transform_data(data):    transformed = data    for index, row in transformed.iterrows():        raw = row['raw']        transformed.loc[index, 'cube'] = np.power(raw, (1 / 3))        transformed.loc[index, 'sqt'] = np.sqrt(raw)        np.seterr(divide='ignore')        transformed.loc[index, 'log10'] = np.where(raw > 0, np.log10(raw), 0)        transformed.loc[index, 'ln'] = np.where(raw > 0, np.log(raw), 0)        transformed.loc[index, 'log2'] = np.where(raw > 0, np.log2(raw), 0)    return transformeddef shift_data(data, data_type: str = 'raw', times: int = 1):    mean_values = data.groupby(['Optimal_Affected_Component_Uid', 'Optimal_Failure'])[data_type].mean().reset_index().sort_values(by=[data_type], ascending=True)    stdev_values = data.groupby(['Optimal_Affected_Component_Uid', 'Optimal_Failure'])[data_type].std().reset_index().fillna(0)    data_new = data.copy()    previous = None    for _, name in mean_values.iterrows():        if previous is not None:            pre_std = stdev_values.loc[(stdev_values['Optimal_Affected_Component_Uid'] == previous[0]) & (stdev_values['Optimal_Failure'] == previous[1])][data_type].tolist()[0]            cur_std = stdev_values.loc[(stdev_values['Optimal_Affected_Component_Uid'] == name[0]) & (stdev_values['Optimal_Failure'] == name[1])][data_type].tolist()[0]            data_new.loc[(data_new['Optimal_Affected_Component_Uid'] == name[0]) & (data_new['Optimal_Failure'] == name[1]), data_type] += (cur_std + pre_std) * times        previous = name    return (mean_values, data_new)def ARCH(e, t, m, s):    return e[-1] + t * (m - e[-1]) + np.random.normal(0., s)def create_non_stationary_data(min_max_sigma_values, function, theta=0.1, N=1000):    '''    :param min_max_sigma_values: a pandas dataframe with the min, max and sigma values for each <component,failure> combination    :param function: the process to create the non-stationary series    :param theta:    :param N: number of series points to create    :return: a pandas dataframe with non-stationary series for each <component,failure> combination    '''    non_stationary_series = pd.DataFrame(columns=['Optimal_Affected_Component_Uid', 'Optimal_Failure', 'value'])    for i, row in min_max_sigma_values.iterrows():        sigma = pow(row[4], 2)        series = create_non_stationary_series_ornstein_uhlenbeck(function, sigma, (sigma/2), theta, row[2], row[3], N)        for s in series:            non_stationary_series.loc[-1] = [row[0], row[1], s]        plt.plot(series)    plt.show()    return non_stationary_seriesdef create_non_stationary_series_ornstein_uhlenbeck(function, sigmaX, sigmaEta, theta, start, mu, N):    '''    :param function: the process to create the non-stationary series    :param sigmaX: the variance of the old dataseries    :param sigmaEta: the new variance    :param theta:    :param start: value to start with, in our scenario the highest value of the original shifted <component,failure> combination    :param mu: value to end with, in our scenario the lowest value of the original shifted <component,failure> combination    :param N: number of series points to create    :return: a non-stationary data series    '''    X = [] #is a random walk    Y = [] #is a function of the random walk and a spread epsilon    epsilon = [start] # non-stationary series    for t in range(N):        if len(X) == 0:            X.append(np.random.normal(10., sigmaX))        else:            X.append(X[-1] + np.random.normal(0., sigmaX))        epsilon.append(function(epsilon, theta, mu, sigmaEta))        Y.append(X[-1] + epsilon[-1])    #X = np.array(X)    #Y = np.array(Y)    return epsilondef perform_ttest(ordering, shifted_data: pd.DataFrame, type: str) -> pd.DataFrame:    ttest_results = pd.DataFrame(columns=['a', 'b', 'statistic', 'pvalue', 'significant'])    data_new_grouped = shifted_data.groupby(['Optimal_Affected_Component_Uid', 'Optimal_Failure'])[type].apply(list).reset_index()    previous = None    for index, name in ordering.iterrows():        if previous is not None:            pre = data_new_grouped.loc[(data_new_grouped['Optimal_Affected_Component_Uid'] == previous[0]) & (data_new_grouped['Optimal_Failure'] == previous[1])][type].tolist()[0]            cur = data_new_grouped.loc[(data_new_grouped['Optimal_Affected_Component_Uid'] == name[0]) & (data_new_grouped['Optimal_Failure'] == name[1])][type].tolist()[0]            result = stats.ttest_ind(pre, cur)            new_row = pd.DataFrame({'a': str(previous), 'b': str(name), 'statistic': result[0], 'pvalue': result[1], 'significant': result[1]<0.025}, index=[0])            ttest_results = ttest_results.append(new_row, ignore_index=True)        previous = name    #ttest_results[ttest_results['statistic']<-0.025][["a", "b", "pvalue"]].to_csv('ttest_results_statisticalSignificant.csv')    #ttest_results.to_csv('ttest_' '_all.csv')    return ttest_results